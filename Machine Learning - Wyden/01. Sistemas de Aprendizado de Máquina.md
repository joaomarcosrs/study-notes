# Identificar conceitos de aprendizado de máquina

* ### Sistemas que pensam como humanos
	Um exemplo são as **redes neurais artificiais**. Esses sistemas automatizam atividades como tomada de decisões, resolução de problemas e aprendizagem. Para isso, é necessário saber como os humanos pensam. Nesse caso, a **modelagem cognitiva** é trabalhada com modelos computacionais de inteligência artificial e técnicas experimentais da Psicologia para construir teorias precisas e verificáveis a respeito dos processos de funcionamento da mente humana. Trabalham com o aprendizado por observação, realizando investigações experimentais de seres humanos ou animais.
	
* ### Sistemas que pensam racionalmente
	São os sistemas inteligentes. Eles tentam simular o pensamento lógico racional dos humanos, isto é, são capazes de fazer as máquinas entender e raciocinar.
	
* ### Sistemas que agem como seres humanos
	Um exemplo são os robôs, máquinas que executam tarefas de um jeito semelhante ao das pessoas. O Teste de Turing, criado em 1950 por Alan Turing, fez com que 30% dos humanos consultados acreditassem que a máquina que participava do teste, ao se fazer passar por humano, era, de fato, um ser humano.
	
* ### Sistemas que agem racionalmente
	São os agentes inteligentes. Idealmente, aqueles que tentam imitar de forma racional o comportamento humano. Agir racionalmente significa agir de modo a alcançar seus objetivos, dadas as suas crenças. Nesse caso, a IA é vista como o estudo e a construção de agentes racionais.

## Desafios do aprendizado de máquina

* ### Qualidade dos dados
	Sabemos que o aprendizado de máquina depende dos dados, pois a partir deles é criado o modelo de aprendizado. Sendo assim, um dos desafios está na qualidade desses dados – os insumos do aprendizado de máquina. Esse é um grande desafio, pois dificilmente uma empresa possui uma base de dados perfeita que possa servir de base para os algoritmos de **machine learning**.

	O aprendizado de máquina utiliza grandes bases de dados, como o **big data**, com potencial para leitura de dados não estruturados. Porém, isso significa a capacidade de armazenar e processar dados diversos, como imagens, textos, voz e vídeos.

	O grande desafio está na organização, ou melhor, na padronização desses dados armazenados. Isso leva tempo e é nesse ponto que muitos projetos de ML acabam nascendo já mortos.

* ### Generalização
	Esse é outro grande desafio. Os algoritmos de **machine learning** devem ser generalizáveis para que tenham resultados em aplicações futuras. Dificilmente uma empresa detém todas as informações necessárias para realizar previsões tão acuradas. Nesse caso, o algoritmo de ML será capaz de generalizar a predição de interesse. Porém, é comum acontecer o **overfitting**.

* ### Profissionais especializados
	No AM, é importante montar um time multidisciplinar, com profissionais que entendam de computação, outros com expertise em estatística, programadores, cientistas de dados, além daqueles que conhecem o negócio.

	O grande desafio está na contratação de profissionais com conhecimento técnico, interessados e esforçados, com ótima capacidade de comunicação, que busquem a resolução do problema, mantendo a base bem-feita. É uma forma muito mais produtiva para interpretar e transferir a mensagem contida nos números.

* ### Ética
	Os parâmetros dos algoritmos de ML nem sempre incluem ética. Um algoritmo pode criar um orçamento nacional com o objetivo de “maximizar o PIB/produtividade no trabalho/expectativa de vida”, mas sem limitações éticas programadas no modelo; pode eliminar orçamentos para escolas, hospitais psiquiátricos e o meio ambiente, porque não aumentam diretamente o PIB.
	
	A inclusão da ética no processamento da máquina se torna um grande desafio. Nesse caso, as questões éticas precisam ser incorporadas e monitoradas ao longo do tempo. Por exemplo, as opiniões sobre questões como os direitos LGBT, matrimônio inter-racial ou entre pessoas de diferentes grupos econômicos podem mudar significativamente de uma geração para outra.

	Se as questões morais variam entre grupos do mesmo país, imagine entre países. Por exemplo, na China, usar o reconhecimento facial para vigilância em massa se tornou a norma. Mas será que outros países veem esse assunto da mesma forma?

* ### Evitar envenenamento dos dados
	Os resultados do aprendizado de máquina dependem muito dos dados de referência, que formam a base do conhecimento. Contudo, os dados podem ficar distorcidos, por acidente ou por conduta duvidosa; este último caso é geralmente chamado de “envenenamento”.

	Se os dados utilizados como amostra de treinamento para um algoritmo de contratação forem obtidos de uma empresa com práticas racistas, eles também serão.

# Reconhecer os métodos de aprendizado de máquina de acordo com o sinal

## Aprendizado de máquina

A definição formal de aprendizado de máquina registra que um programa de computador “aprende” a respeito de uma **tarefa T**, por meio de uma **experiência E**, em relação a uma **métrica de** **desempenho P**, se o seu desempenho na **tarefa T**, quando medido pela **métrica P**, aumenta com a **experiência E.**
##### Métodos de Machine Learning
1. **Supervisionado**
2. **Não Supervisionado**
3. **Semissupervisionado**
4. **Por Reforço**
### Supervisionado
Os algoritmos de AM supervisionado utilizam uma série de experiências ou exemplos **(entradas)** rotulados com suas respectivas classes **(saídas)**, para aprender padrões dentre esses dados e, assim, **formular um modelo de conhecimento** para classificar novas entradas.
##### Possui duas fases:
1. É a formulação do modelo, chamada de treinamento.
2. É o teste, quando o modelo é usado para identificar corretamente os dados de fora do conjunto de treinamento e não rotulados.
##### A estimativa do rótulo se dá de duas maneiras:
* **Classificação**
	Quando se estima com base em um **conjunto finito de rótulos**, que pode ser utilizado para classificar produtos defeituosos, clientes inadimplentes etc.
* **Regressão**
	Quando se estimam **valores reais**, por exemplo, o número de vendas, quantidade de matéria-prima necessária para um determinado período, número de produtos com defeito etc.

Dessa maneira, se o rótulo é um **número real**, a tarefa chama-se regressão. Se o rótulo vem de um **conjunto finito e não ordenado**, então a tarefa chama-se classificação.

### Aprendizado de máquina não supervisionado
Ao contrário do aprendizado supervisionado que acabamos de discutir, no aprendizado não supervisionado não existem experiências predefinidas a serem utilizadas como referência para aprender.

Os algoritmos de AM não supervisionados utilizam conjunto de dados de entrada não rotulados **(sem um resultado conhecido)** e, apenas com base em suas características, aprendem a detectar **agrupamentos implícitos** ou **características** especialmente úteis para a sua categorização.

###  Aprendizado semissupervisionado
Esse aprendizado utiliza tanto o conjunto de dados rotulados como também o conjunto de dados não rotulados.

No caso de dados rotulados, pode-se utilizar aprendizado supervisionado para induzir classificadores a partir desses dados. Ao contrário, quando os rótulos dos dados não estão definidos, pode-se utilizar aprendizado não supervisionado com o objetivo de encontrar _clusters_, ou seja, agrupamento entre os dados por semelhança.

> **Obs.:** 
> O aprendizado semissupervisionado consiste em utilizar algoritmos que aprendem a partir de exemplos rotulados e não rotulados. Isso se deve ao fato de existirem em abundância dados não rotulados e os rotulados geralmente serem mais escassos.

* #### Algoritmos de Classificação Semissupervisionados
	Rotulam, com uma certa margem de segurança, alguns dos dados no conjunto de dados não rotulados, os quais são posteriormente utilizados durante a **fase de treinamento do classificador**, gerando, assim, uma classificação mais precisa.
* #### Algoritmos de Clusterização Semissupervisionados
	Os dados rotulados são utilizados no processo de criação dos _clusters_, servindo como conhecimento expresso na forma de restrições e, dessa forma, resultando em melhores _clusters_.

### Aprendizado por reforço
O entendimento do conceito de aprendizado por reforço fica mais fácil com a ajuda da Psicologia, cuja corrente denominada behaviorismo define o comportamento humano como resultado das influências do ambiente. Sendo assim, **podemos entender que o comportamento pode ser moldado de acordo com estímulos e respostas**.

Aprendizado por reforço é uma área do AM que avalia como a máquina deve agir em determinados ambientes de acordo com as recompensas ou punições recebidas e acumuladas com o tempo.

> **Obs.:**
> A máquina aprende **executando ações** e **avaliando recompensas**. Primeiramente ela observa o ambiente e seu conjunto de cenários futuros possíveis. Com base nisso, escolhe uma ação a ser executada e recebe a recompensa associada a ela. O processo se repete até que a máquina seja capaz de escolher a melhor ação para cada um dos cenários possíveis. E isso vai depender das circunstâncias nas quais a ação será executada. Ou seja, uma recompensa ou punição é dada à máquina, dependendo da decisão tomada.

#### Exemplo para entender exploration vs. explotation
Adestramento de cães; suponha que, depois de ensinar um cachorro a sentar com sucesso, o tutor queira fazer um teste de obediência – manter o cão sentado enquanto anda para trás, até chegar a uma distância de cinco metros dele. Caso o cão se sente, ele ganha o biscoitinho (assim como antes); caso ele não se levante até o tutor ficar a cinco metros dele, o cão recebe uma recompensa maior (um pedaço de carne, por exemplo).

Essa situação ilustra um _trade-off_: o animal pode escolher por “testar” novas combinações de ações ótimas em uma sequência de “estados” não realizada anteriormente, em busca de uma recompensa maior, mas não imediata (o chamado _exploration_); ou simplesmente se ater à recompensa que ele pode obter por meio de uma ação já conhecida (o chamado _exploitation_).

Fazer a máquina ser capaz de encontrar o meio termo ótimo entre _exploration_ e _exploitation_ é um dos principais desafios do aprendizado por reforço, e é bastante pertinente para aplicações mais complicadas, como ensinar uma máquina a jogar xadrez, por exemplo.
# Distinguir as categorias de problemas de aprendizado de máquina em função da saída

O aprendizado de máquina automatiza a criação de modelos analíticos utilizados para **predição**, **simulação** e **análise de dados**. Dessa forma, os sistemas são capazes de aprender com o conjunto de dados, identificar padrões, além de auxiliar na tomada de decisão.

O AM pode ser realizado de duas maneiras, na predição ou no auxílio da descrição dos dados:

![](https://raw.githubusercontent.com/joaomarcosrs/study-notes/main/Machine%20Learning%20-%20Wyden/static/img_01_01.jpg "Imagem: Daisy Albuquerque, adaptado por Heloise Godinho")

## Modelo preditivo
É usado pelo aprendizado supervisionado com foco em predizer os rótulos desconhecidos. Na prática, o aprendizado supervisionado utiliza os dados para aprender como resolver determinado problema, que pode ser de classificação ou de regressão.
### Classificação
Os problemas de classificação são aqueles que buscam encontrar uma classe, dentro das possibilidades existentes. A ideia é prever os resultados em uma saída discreta, a partir do mapeamento de variáveis de entrada em categorias distintas.
### Regressão
Os problemas de regressão são aqueles que precisam prever um valor numérico específico. Nesse caso, a ideia é prever os resultados em uma saída contínua, o que significa mapear variáveis de entrada para uma função contínua.

## Modelo descritivo
O AM não supervisionado descobre padrões previamente desconhecidos em dados. Como não se sabe quais devem ser os resultados, ainda não há como determinar a precisão deles, tornando o aprendizado de máquina não supervisionado mais aplicável aos problemas do mundo real do que os outros tipos de aprendizado de máquina.
### Clustering
Uma das principais categorias utilizadas pelo aprendizado de máquina não supervisionado é a clusterização (_clustering_), que divide automaticamente o conjunto de dados em grupos, de acordo com a similaridade.
### Estimativas de densidade
Esse método tem por base a função densidade de probabilidade – conceito fundamental em estatística. Nele se identificam as regiões densas, permitindo a formação de grupos com diferentes formatos.

Podemos então definir esse método como uma técnica não paramétrica para estimação de curvas de densidades, em que cada observação é ponderada pela distância em relação a um valor central, o núcleo.

O método usa o valor de densidade para agrupar aqueles pontos que têm valores similares. Dessa maneira, é possível identificar vizinhanças densas nas quais a maioria dos pontos está contida.
### Redução dimensional
O método de redução dimensional se aplica quando temos um conjunto de dados com uma quantidade de variáveis bem grande em um problema.

Às vezes, **há muitas variáveis altamente correlacionadas**, ou seja, elas são redundantes ou são variáveis que não apresentam informações úteis ao problema. Essa situação faz o modelo selecionado apresentar muitos parâmetros, e pode acabar causando _overfitting_, significando que o modelo tem um desempenho excelente no treino, porém quando o utilizamos em dados de teste, o resultado é ruim.
