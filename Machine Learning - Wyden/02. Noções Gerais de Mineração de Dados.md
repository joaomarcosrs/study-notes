# Definir a Descoberta de Conhecimento em Bases de Dados (KDD)
**KDD** se refere ao conjunto de passos e/ou processos que visam a descoberta de conhecimento útil a partir dos dados, enquanto **Data Mining** vem a ser uma etapa desse processo de descobrimento envolvendo a fase de modelagem dos dados.
### Características
* #### Iterativo
	Porque prevê uma sequência de atividades em que o resultado de uma etapa (iteração) depende da outra.
* #### Interativo
	Porque o analista pode intervir nas atividades, interagindo no processo. Cada etapa do processo pode ser repetida inúmeras vezes.

## Relacionamento entre KDD, Data Mining e Machine Learning

### Machine Learning
**Machine Learning** é uma das áreas da Inteligência Artificial que, de maneira considerável, vem ganhando espaço no mercado, graças aos avanços dos estudos e tecnologias da Internet das Coisas (IoT) e de Big Data.

Com esse aprendizado, os computadores podem identificar padrões entre os dados analisados e, por meio da aplicação de algoritmos especiais, serem treinados a aprenderem sozinhos, a fim de executar uma tarefa.

_Softwares_ capazes de aprender com a experiência e informações inerentes a um grande volume de dados nos ajudam a definir o aprendizado de máquina. O objetivo é a criação de técnicas computacionais que visam o aprendizado e a construção de sistemas inteligentes com a capacidade de adquirir conhecimento de forma automática.

### Data Mining
O *Data Mining* ou **Mineração de Dados** é o ramo da área de Banco de Dados que utiliza técnicas e algoritmos para extrair informações relevantes de uma base de dados densamente povoada. Portanto, nada mais é que uma das técnicas para obtermos conhecimento em base de dados, permitindo que possamos descobrir conhecimento que esteja implícito no agrupamento de dados.

# Identificar as etapas do processo de KDD
* #### **_Data_ (dados)**
	São acessíveis a todos e disponíveis em todos os lugares. Sendo assim, valem menos que a informação.
* #### **_Information_ (informação)**
	É a interpretação dos dados. Ela manipula os dados de relevância e de propósito, atribuindo-lhes um significado.
* #### **_Knowledge_ (conhecimento)**
	É oriundo da contextualização, organização e padronização da informação.
* #### **_Wisdom_ (sabedoria)**
	É o resultado que se alcança através da análise e da formulação de hipóteses perante cenários distintos.

## Etapas do processo de KDD
Segundo Fayyad, Piatetsky-Shapiro e Smyth, numa visão acadêmica, o processo de KDD é composto por cinco fases, conforme visualizamos a seguir:

![[img_02_01.jpg]]

* #### Seleção
	Diante da enorme massa de dados armazenados em repositórios diversos (banco de dados, relatórios, transações, logs de acessos, redes sociais, sistemas de gestão de relacionamento com o cliente - CRM), cria-se uma segmentação, de acordo com critérios, determinando o conjunto de dados-alvo em que a descoberta deve ser realizada.
* #### Pré-processamento e limpeza
	Adequação, limpeza e formatação dos dados para ferramenta de mineração, ==removendo ruídos, redundâncias e realizando manipulações, quando necessárias, reduzindo as variáveis do conjunto de dados==, de acordo com os objetivos em questão.
* #### Transformação
	Os dados são apropriadamente transformados para mineração, por meio da realização de operações de agregação, por exemplo.
* #### Data Mining
	A partir dos repositórios organizados, são feitos ajustes de parâmetros para a execução efetiva de um ou mais algoritmos sofisticados a fim de ==extrair o padrão de comportamento dos dados==, de forma interativa.
* #### Interpretação e Avaliação
	Classificação, consolidação, análise e compreensão aprofundada dos padrões, tendências e seus significados, ==desconsiderando aquilo que é específico, reconhecendo fatos significativos e valorizando o que é generalizado==, de maneira a dar suporte à tomada de decisões.
### Pré-processamento
A etapa de pré-processamento compreende todas as funções relacionadas com a captação, organização e tratamento dos dados. Esta etapa tem como objetivo a preparação dos dados para os algoritmos de mineração de dados que serão aplicados na etapa seguinte.

As principais funções de **pré-processamento** são:
* #### Seleção de dados
	A Seleção de Dados é constituída por um agrupamento organizado de uma massa de dados, alvo da prospecção. Nessa fase, é feita a escolha dos dados que realmente serão utilizados no processo. A seleção dos dados pode ter dois enfoques distintos: a seleção de atributos ou a seleção de registros que devem ser submetidos ao processo de extração de conhecimento. Nesse estágio, é interessante a participação de um especialista no conjunto de dados, uma vez que essa seleção é de fundamental impacto nos resultados das análises.
* #### Limpeza dos dados
	A Limpeza dos Dados tem como finalidade eliminar essas adversidades de forma que elas não influenciem nos resultados. Algumas das causas desses problemas são erros humanos (erros de digitação, por exemplo), indisponibilidade da informação no momento do levantamento dos dados ou quando alguma mudança no sistema operacional ainda não tenha sido refletida no ambiente da Mineração de Dados.
* #### Integração dos dados
	A Integração dos Dados analisa profundamente os dados coletados para que se possa integrá-los de forma consistente e apta à obtenção de resultados satisfatórios. Redundâncias, dependências entre as variáveis e valores incompatíveis (categorias diferentes para os mesmos valores ou regras diferentes para os mesmos dados, por exemplo) são algumas técnicas observadas e corrigidas na integração dos dados.
* #### Transformação dos dados
	A Transformação dos Dados é a etapa mais importante do pré-processamento, pois é por meio dela que se constitui um padrão para os dados, facilitando o uso das técnicas computacionais de análise. Na etapa de Transformação, os dados pré-processados passam por tratamento para um armazenamento adequado, visando facilitar o uso das técnicas de **Data Mining**, pois existem diversos tipos de algoritmos e cada um necessita de uma entrada específica, além das conversões de dados, criação de novas variáveis e categorização de variáveis contínuas.
* #### Redução dos dados
	A Redução dos Dados é essencial para que análises sejam feitas de forma a se obter resultados satisfatórios, ainda que feita a seleção dos dados no início, pois quando as bases de dados são muito grandes, a mineração torna-se inviável.

### Mineração de Dados
A etapa de Mineração de Dados ou Data Mining, basicamente, utiliza os repositórios organizados para a execução de algoritmos de complexos com o objetivo de extrair padrões de comportamento e associações entre os dados de forma interativa.

Sendo assim, esta etapa consiste no uso de técnicas que permitem automatizar a busca em grandes volumes de dados por padrões e tendências que não são detectáveis por análises mais simples, auxiliando gestores na tomada de decisões estratégicas.
#### As tarefas mais comuns aplicadas na prática de Mineração de Dados incluem:
* ##### Sumarização
* ##### Classificação
* ##### Regressão e Estimação
* ##### Predição
* ##### Agrupamento ou Clusterização
* ##### Associações
* ##### Detecção de Desvios
* ##### Descoberta de Sequências
### Pós-processamento
A etapa de pós-processamento é referente a **interpretação e avaliação dos dados minerados**.

Segundo Goldschmidt, Bezerra e Passos (2015), a etapa do pós-processamento abrange o tratamento do conhecimento adquirido na etapa de mineração de dados. Entre as principais funções desta etapa, destacam-se a elaboração e organização do conhecimento obtido, podendo incluir a simplificação de gráficos, diagramas e relatórios, além da conversão da forma de representação em conhecimento obtido.

Há muitas propostas na literatura para “minerar” o conhecimento descoberto, ou seja, pós-processar o conhecimento descoberto pela etapa de Data Mining.

Em geral, as propostas se enquadram em duas categorias básicas:
* #### Subjetivo
	No método subjetivo, é preciso que o usuário estabeleça previamente o conhecimento ou crenças, a partir do qual o sistema irá minerar o conjunto original de padrões descoberto pelo algoritmo de Data Mining, buscando por aqueles padrões que sejam surpreendentes ao usuário.
* #### Objetivo
	O método objetivo não necessita que um conhecimento prévio seja estabelecido. Pode-se dizer que o método objetivo é dirigido por dados (_data-driven_) e o subjetivo é dirigido pelo usuário (_user-driven_).
# Descrever as técnicas de mineração de dados

*Quanto mais complexas são as bases de dados coletadas, mais potencial há para delas extrair insights relevantes.*

A **mineração de dados** é um termo usado para generalizar todas as técnicas e métodos computacionais usados para analisar e extrair informação de bases de dados, ou seja, é uma extração de informação com o objetivo de descobrir padrões válidos e potencialmente úteis, o que seria impossível por meio de uma observação mais superficial.

*Sendo assim, o termo mineração de dados pode ser considerado a etapa de aplicação de técnicas ou ferramentas par
a apresentar e analisar os dados.*

## Algoritmos baseados em modelos preditivos e modelos descritivos

A **Mineração de Dados** possui como premissa básica a argumentação ativa, ou seja, em vez do usuário definir o problema, selecionar os dados e as ferramentas para analisá-los, as ferramentas de MD extraem automaticamente dos dados anomalias e possíveis associações para identificar problemas que não tinham sido visualizados pelo usuário.

*Em resumo, as ferramentas de Mineração de Dados analisam os dados, descobrem problemas ou oportunidades de melhorias nas associações entre os dados, para diagnosticar o comportamento dos negócios, requerendo a mínima intervenção do usuário.*

### Modelo Preditivo
* #### Classificação
	A classificação prediz associações dos dados entre as classes. Por exemplo, por esse modelo, é possível predizer a probabilidade de uma pessoa ir ou não jogar tênis, responder ou não a uma solicitação, analisar se tem um baixo ou alto risco de crédito etc.
* #### Predição
	A regressão prediz um número — por exemplo, qual o valor do aluguel de um imóvel, qual a receita gerada pelo cliente no próximo ano ou qual a vida útil de um equipamento (número de meses antes de falhar).
* #### Estimação
	 A estimação prediz algum valor baseado num padrão já conhecido — por exemplo, conhecendo o padrão de despesas e a idade de uma pessoa, é possível estimar seu salário e seu número de filhos.

*Algoritmos de modelagem preditiva mais utilizados:*
#### Árvores de decisão
Os algoritmos de árvores de decisão, ou **Decision Trees**, são algoritmos de Machine Learning largamente utilizados, com uma estrutura de simples compreensão e que costumam apresentar bons resultados em suas previsões. Eles também são a base do funcionamento de outros algoritmos, como o **Random Forest**.

Em uma árvore de decisão, cada ramo representa uma escolha entre um número de alternativas e cada folha, uma classificação ou decisão. Esse modelo analisa os dados e tenta encontrar a variável que divide os dados em classes diferentes.
#### Regressão
A análise de regressão é um método estatístico que permite examinar a relação entre duas ou mais variáveis. Sendo assim, este algoritmo trabalha com dados contínuos que podem seguir uma distribuição normal, encontrando padrões essenciais em grandes bases de dados.

Por exemplo, usa-se esse algoritmo quando se deseja determinar quanto cada fator específico, como o preço, influência o movimento de um ativo.

*A regressão linear pode ser dividida em:*
- ##### Regressão linear simples
	Uma variável independente é usada para prever o resultado.
- ##### Regressão linear múltipla
	Usa duas ou mais variáveis independentes para prever o resultado.

Na **regressão logística**, valores desconhecidos de uma variável discreta são previstos com base no valor conhecido de outras variáveis.

Ou seja, a regressão logística mede a relação entre a variável dependente categórica e uma ou mais variáveis independentes, estimando as probabilidades usando uma função logística.

Sendo assim, o algoritmo de Machine Learning analisa diferentes aspectos ou variáveis de um objeto para depois determinar uma classe na qual ele se encaixa melhor.

*Há três modelos de regressão logística:*
* ##### Regressão logística binominal
	Os dados são classificados em dois grupos ou categorias. Por exemplo, a mensagem é _spam_ ou não.
* ##### Regressão logística ordinal
	Os dados são classificados em três ou mais classes em uma ordem já determinada. Por exemplo, o desempenho do atleta é ruim, justo ou excelente.
* ##### Regressão logística multinomial
	Os dados são classificados em três ou mais categorias sem ordem entre si. Por exemplo, o animal é um gato, um leão ou um tigre.

#### Redes neurais artificiais
As **Redes Neurais Artificiais (RNA)** são modelos mais complexos e sofisticados. Eles são capazes de modelar relações extremamente complexas.

Os algoritmos de RNA apresentam um modelo matemático inspirado na estrutura neural de organismos inteligentes e adquirem conhecimento por meio da experiência.

Uma grande RNA pode ter centenas ou milhares de unidades de processamento; já o cérebro de um mamífero pode ter muitos bilhões de neurônios.

Os algoritmos de RNA também são populares porque são poderosas e flexíveis. Seu poder vem de sua capacidade de lidar com relações não lineares em dados, o que é cada vez mais comum à medida que coletamos mais dados.

Uma RNA é composta por várias unidades de processamento, cujo funcionamento é bastante simples. Essas unidades, geralmente, são conectadas por canais de comunicação que estão associados a determinado peso. As unidades fazem operações apenas sobre seus dados locais, que são entradas recebidas pelas suas conexões. O comportamento inteligente de uma Rede Neural Artificial vem das interações entre as unidades de processamento da rede.

Arquiteturas neurais são tipicamente organizadas em camadas, com unidades que podem estar conectadas às unidades da camada posterior, conforme é visualizado a seguir:

![[img_02_02.jpg]]

### Modelo Descritivo
O Modelo Descritivo representa a área de investigação de dados que busca tanto descrever fatos relevantes, não triviais e desconhecidos dos usuários, como analisar a base de dados, principalmente pelo seu aspecto de qualidade, para validar todo o processo da mineração.

O modelo consiste em estudar tudo que tem a ver com o passado. Sendo assim, é usado para descrever os eventos que ocorreram de acordo com os parâmetros e referências usados na tomada de decisão. Podemos subdividi-lo em:

* #### **Agrupamento**
	Os dados são agrupados de acordo com a sua similaridade.
* #### **Sumarização**
	O objetivo é encontrar uma descrição simples e compacta para os dados.
* #### **Associação**
	Deve-se encontrar padrões para associar os atributos dos dados.

*Alguns algoritmos de modelagem descritiva mais utilizados são:*
#### Expectation-Maximization (EM)
A técnica da **Expectância Máxima** é usada para estimar funções de máxima semelhança. Esta técnica retorna bons resultados sobre bases com dados incompletos, pois pode-se utilizar os valores aprendidos com os dados preenchidos para estimar os valores ausentes (SILVA; JÚNIOR; SILVA, 2016).
#### K-means
O algoritmo k-Médias possui uma implementação relativamente simples, o que ajuda a tornar seu uso mais difundido. Esta técnica utiliza centroides, que representam a instância média de um grupo. Para realizar o agrupamento, o método utiliza alguma medida de similaridade entre as instâncias. Normalmente, essa medida é a distância euclidiana (SILVA; JÚNIOR; SILVA,2016).
#### Hierárquico (H)
O algoritmo hierárquico, que pode ser aglomerativo ou divisivo, trabalha criando uma sequência de partições, como uma árvore (FACELI et al.,2015). No **divisivo**, as instâncias são colocadas em um único grupo e são divididas até que o número de grupos seja o desejado. Já no **aglomerativo**, as instâncias iniciam sendo, cada uma, um grupo e são agrupadas iterativamente até que se tenha o número de grupos desejado (SILVA; JÚNIOR; SILVA,2016).
## Técnicas de mineração de dados não estruturados

*Para a mineração de dados não estruturados, são utilizadas as seguintes técnicas:*

* #### Processamento de Linguagem Natural (PLN)
	É um ramo da Inteligência Artificial que auxilia as máquinas a entenderem, interpretarem e manipularem a linguagem humana.
	Por exemplo, quando você fala para a Alexa (assistente virtual desenvolvida pela Amazon) que gosta de uma determinada música, o assistente virtual irá entender e executar a ação de salvar sua classificação, retornando uma mensagem de voz que simula a de um ser humano.
* #### Recuperação de Informações
	É uma técnica que utiliza métodos e medidas estatísticas ou semânticas para processar textos e encontrar quais documentos possuem respostas para a questão.
* #### Extração de Informação
	É a técnica que busca partes relevantes de um texto em um documento e extrai informações específicas.